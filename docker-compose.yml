version: "3"

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-net

  datanode-1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-1
    restart: always
    hostname: datanode-1
    ports:
      - 9864:9864
    volumes:
      - hadoop_datanode-1:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-net
  datanode-2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-2
    restart: always
    hostname: datanode-2
    ports:
      - 50075:9864
    volumes:
      - hadoop_datanode-2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-net
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode-1:9864"
    env_file:
      - ./hadoop.env
    ports:
      - 8088:8088
    networks:
      - hadoop-net
  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode-1:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-net
    
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode-1:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    networks:
      - hadoop-net
  spark-master:
    image: bitnami/spark:3.4.0
    container_name: spark-master
    hostname: spark-master
    restart: always
    ports:
      - 8080:8080  # Spark UI
      - 7077:7077  # Spark Master Port
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    # volumes:
    #   - ./hadoop-config:/opt/hadoop/etc/hadoop
    depends_on:
      - namenode
      - datanode-1
      - datanode-2
    networks:
      - hadoop-net
  spark-worker:
    image: bitnami/spark:3.4.0
    container_name: spark-worker
    restart: always
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    # volumes:
    #   - ./hadoop-config:/opt/hadoop/etc/hadoop
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      - hadoop-net
  jupyter:
    image: jupyter/pyspark-notebook:spark-3.4.0
    container_name: jupyter
    ports:
      - "8888:8888"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - PYSPARK_PYTHON=python3.9
      - PYSPARK_DRIVER_PYTHON=python3.9
      - PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --ip=0.0.0.0 --allow-root --NotebookApp.token='
      # - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
      # - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    depends_on:
      - spark-master
    networks:
      - hadoop-net
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./hadoop-config:/opt/hadoop/etc/hadoop
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.14
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
      - xpack.security.transport.ssl.enabled=false
    ports:
      - "9200:9200"
    networks:
      - hadoop-net
    healthcheck:
      test: curl -s http://localhost:9200/_cluster/health | grep -q '"status":"green"'
      interval: 20s
      timeout: 10s
      retries: 10

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.14
    container_name: kibana
    environment:
      ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - hadoop-net
networks:
  hadoop-net:
    driver: bridge
volumes:
  hadoop_namenode:
  hadoop_datanode-1:
  hadoop_datanode-2:
  hadoop_historyserver:
  elastic_data:
